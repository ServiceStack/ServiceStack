/* Options:
Date: 2025-11-03 11:38:42
Version: 8.91
Tip: To override a DTO option, remove "//" prefix before updating
BaseUrl: https://localhost:5001

//GlobalNamespace: 
//MakePropertiesOptional: False
//AddServiceStackTypes: True
//AddResponseStatus: False
//AddImplicitVersion: 
//AddDescriptionAsComments: True
IncludeTypes: ChatCompletion.*
//ExcludeTypes: 
//DefaultImports: 
*/

package dtos


type IReturn struct {
}

type IPost struct {
}

// @DataContract
type AiContent struct {
    /** @description The type of the content part. */
    // @DataMember(Name="type")
    Type string `json:"type"`
}

/** @description The tool calls generated by the model, such as function calls. */
// @DataContract
type ToolCall struct {
    /** @description The ID of the tool call. */
    // @DataMember(Name="id")
    Id string `json:"id"`
    /** @description The type of the tool. Currently, only `function` is supported. */
    // @DataMember(Name="type")
    Type string `json:"type"`
    /** @description The function that the model called. */
    // @DataMember(Name="function")
    Function string `json:"function"`
}

/** @description A list of messages comprising the conversation so far. */
// @DataContract
type AiMessage struct {
    /** @description The contents of the message. */
    // @DataMember(Name="content")
    Content []AiContent `json:"content,omitempty"`
    /** @description The role of the author of this message. Valid values are `system`, `user`, `assistant` and `tool`. */
    // @DataMember(Name="role")
    Role string `json:"role"`
    /** @description An optional name for the participant. Provides the model information to differentiate between participants of the same role. */
    // @DataMember(Name="name")
    Name *string `json:"name,omitempty"`
    /** @description The tool calls generated by the model, such as function calls. */
    // @DataMember(Name="tool_calls")
    ToolCalls []ToolCall `json:"tool_calls,omitempty"`
    /** @description Tool call that this message is responding to. */
    // @DataMember(Name="tool_call_id")
    ToolCallId *string `json:"tool_call_id,omitempty"`
}

/** @description Parameters for audio output. Required when audio output is requested with modalities: [audio] */
// @DataContract
type AiChatAudio struct {
    /** @description Specifies the output audio format. Must be one of wav, mp3, flac, opus, or pcm16. */
    // @DataMember(Name="format")
    Format string `json:"format"`
    /** @description The voice the model uses to respond. Supported voices are alloy, ash, ballad, coral, echo, fable, nova, onyx, sage, and shimmer. */
    // @DataMember(Name="voice")
    Voice string `json:"voice"`
}

type ResponseFormat string

const (
    ResponseFormatText ResponseFormat = "text"
    ResponseFormatJsonObject = "json_object"
)

// @DataContract
type AiResponseFormat struct {
    /** @description An object specifying the format that the model must output. Compatible with GPT-4 Turbo and all GPT-3.5 Turbo models newer than gpt-3.5-turbo-1106. */
    // @DataMember(Name="response_format")
    ResponseFormat ResponseFormat `json:"response_format,omitempty"`
}

type ToolType string

const (
    ToolTypeFunction ToolType = "function"
)

// @DataContract
type Tool struct {
    /** @description The type of the tool. Currently, only function is supported. */
    // @DataMember(Name="type")
    Type ToolType `json:"type,omitempty"`
}

// @DataContract
type ResponseError struct {
    // @DataMember(Order=1)
    ErrorCode string `json:"errorCode"`
    // @DataMember(Order=2)
    FieldName string `json:"fieldName"`
    // @DataMember(Order=3)
    Message string `json:"message"`
    // @DataMember(Order=4)
    Meta map[string]string `json:"meta,omitempty"`
}

// @DataContract
type ResponseStatus struct {
    // @DataMember(Order=1)
    ErrorCode string `json:"errorCode"`
    // @DataMember(Order=2)
    Message *string `json:"message,omitempty"`
    // @DataMember(Order=3)
    StackTrace *string `json:"stackTrace,omitempty"`
    // @DataMember(Order=4)
    Errors []ResponseError `json:"errors,omitempty"`
    // @DataMember(Order=5)
    Meta map[string]string `json:"meta,omitempty"`
}

/** @description Annotations for the message, when applicable, as when using the web search tool. */
// @DataContract
type UrlCitation struct {
    /** @description The index of the last character of the URL citation in the message. */
    // @DataMember(Name="end_index")
    EndIndex int `json:"end_index,omitempty"`
    /** @description The index of the first character of the URL citation in the message. */
    // @DataMember(Name="start_index")
    StartIndex int `json:"start_index,omitempty"`
    /** @description The title of the web resource. */
    // @DataMember(Name="title")
    Title string `json:"title"`
    /** @description The URL of the web resource. */
    // @DataMember(Name="url")
    Url string `json:"url"`
}

/** @description Annotations for the message, when applicable, as when using the web search tool. */
// @DataContract
type ChoiceAnnotation struct {
    /** @description The type of the URL citation. Always url_citation. */
    // @DataMember(Name="type")
    Type string `json:"type"`
    /** @description A URL citation when using web search. */
    // @DataMember(Name="url_citation")
    UrlCitation UrlCitation `json:"url_citation"`
}

/** @description If the audio output modality is requested, this object contains data about the audio response from the model. */
// @DataContract
type ChoiceAudio struct {
    /** @description Base64 encoded audio bytes generated by the model, in the format specified in the request. */
    // @DataMember(Name="data")
    Data string `json:"data"`
    /** @description The Unix timestamp (in seconds) for when this audio response will no longer be accessible on the server for use in multi-turn conversations. */
    // @DataMember(Name="expires_at")
    ExpiresAt int `json:"expires_at,omitempty"`
    /** @description Unique identifier for this audio response. */
    // @DataMember(Name="id")
    Id string `json:"id"`
    /** @description Transcript of the audio generated by the model. */
    // @DataMember(Name="transcript")
    Transcript string `json:"transcript"`
}

// @DataContract
type ChoiceMessage struct {
    /** @description The contents of the message. */
    // @DataMember(Name="content")
    Content string `json:"content"`
    /** @description The refusal message generated by the model. */
    // @DataMember(Name="refusal")
    Refusal *string `json:"refusal,omitempty"`
    /** @description The reasoning process used by the model. */
    // @DataMember(Name="reasoning")
    Reasoning *string `json:"reasoning,omitempty"`
    /** @description The role of the author of this message. */
    // @DataMember(Name="role")
    Role string `json:"role"`
    /** @description Annotations for the message, when applicable, as when using the web search tool. */
    // @DataMember(Name="annotations")
    Annotations []ChoiceAnnotation `json:"annotations,omitempty"`
    /** @description If the audio output modality is requested, this object contains data about the audio response from the model. */
    // @DataMember(Name="audio")
    Audio *ChoiceAudio `json:"audio,omitempty"`
    /** @description The tool calls generated by the model, such as function calls. */
    // @DataMember(Name="tool_calls")
    ToolCalls []ToolCall `json:"tool_calls,omitempty"`
}

// @DataContract
type Choice struct {
    /** @description The reason the model stopped generating tokens. This will be stop if the model hit a natural stop point or a provided stop sequence, length if the maximum number of tokens specified in the request was reached, content_filter if content was omitted due to a flag from our content filters, tool_calls if the model called a tool */
    // @DataMember(Name="finish_reason")
    FinishReason string `json:"finish_reason"`
    /** @description The index of the choice in the list of choices. */
    // @DataMember(Name="index")
    Index int `json:"index,omitempty"`
    /** @description A chat completion message generated by the model. */
    // @DataMember(Name="message")
    Message ChoiceMessage `json:"message"`
}

/** @description Usage statistics for the completion request. */
// @DataContract
type AiCompletionUsage struct {
    /** @description When using Predicted Outputs, the number of tokens in the prediction that appeared in the completion. */
    // @DataMember(Name="accepted_prediction_tokens")
    AcceptedPredictionTokens int `json:"accepted_prediction_tokens,omitempty"`
    /** @description Audio input tokens generated by the model. */
    // @DataMember(Name="audio_tokens")
    AudioTokens int `json:"audio_tokens,omitempty"`
    /** @description Tokens generated by the model for reasoning. */
    // @DataMember(Name="reasoning_tokens")
    ReasoningTokens int `json:"reasoning_tokens,omitempty"`
    /** @description When using Predicted Outputs, the number of tokens in the prediction that did not appear in the completion. */
    // @DataMember(Name="rejected_prediction_tokens")
    RejectedPredictionTokens int `json:"rejected_prediction_tokens,omitempty"`
}

/** @description Breakdown of tokens used in the prompt. */
// @DataContract
type AiPromptUsage struct {
    /** @description When using Predicted Outputs, the number of tokens in the prediction that appeared in the completion. */
    // @DataMember(Name="accepted_prediction_tokens")
    AcceptedPredictionTokens int `json:"accepted_prediction_tokens,omitempty"`
    /** @description Audio input tokens present in the prompt. */
    // @DataMember(Name="audio_tokens")
    AudioTokens int `json:"audio_tokens,omitempty"`
    /** @description Cached tokens present in the prompt. */
    // @DataMember(Name="cached_tokens")
    CachedTokens int `json:"cached_tokens,omitempty"`
}

/** @description Usage statistics for the completion request. */
// @DataContract
type AiUsage struct {
    /** @description Number of tokens in the generated completion. */
    // @DataMember(Name="completion_tokens")
    CompletionTokens int `json:"completion_tokens,omitempty"`
    /** @description Number of tokens in the prompt. */
    // @DataMember(Name="prompt_tokens")
    PromptTokens int `json:"prompt_tokens,omitempty"`
    /** @description Total number of tokens used in the request (prompt + completion). */
    // @DataMember(Name="total_tokens")
    TotalTokens int `json:"total_tokens,omitempty"`
    /** @description Breakdown of tokens used in a completion. */
    // @DataMember(Name="completion_tokens_details")
    CompletionTokensDetails *AiCompletionUsage `json:"completion_tokens_details,omitempty"`
    /** @description Breakdown of tokens used in the prompt. */
    // @DataMember(Name="prompt_tokens_details")
    PromptTokensDetails *AiPromptUsage `json:"prompt_tokens_details,omitempty"`
}

/** @description Text content part */
// @DataContract
type AiTextContent struct {
    AiContent
    /** @description The text content. */
    // @DataMember(Name="text")
    Text string `json:"text"`
}

// @DataContract
type AiImageUrl struct {
    /** @description Either a URL of the image or the base64 encoded image data. */
    // @DataMember(Name="url")
    Url string `json:"url"`
}

/** @description Image content part */
// @DataContract
type AiImageContent struct {
    AiContent
    /** @description The image for this content. */
    // @DataMember(Name="image_url")
    ImageUrl AiImageUrl `json:"image_url"`
}

/** @description Audio content part */
// @DataContract
type AiInputAudio struct {
    /** @description URL or Base64 encoded audio data. */
    // @DataMember(Name="data")
    Data string `json:"data"`
    /** @description The format of the encoded audio data. Currently supports 'wav' and 'mp3'. */
    // @DataMember(Name="format")
    Format string `json:"format"`
}

/** @description Audio content part */
// @DataContract
type AiAudioContent struct {
    AiContent
    /** @description The audio input for this content. */
    // @DataMember(Name="input_audio")
    InputAudio AiInputAudio `json:"input_audio"`
}

/** @description File content part */
// @DataContract
type AiFile struct {
    /** @description The URL or base64 encoded file data, used when passing the file to the model as a string. */
    // @DataMember(Name="file_data")
    FileData string `json:"file_data"`
    /** @description The name of the file, used when passing the file to the model as a string. */
    // @DataMember(Name="filename")
    Filename string `json:"filename"`
    /** @description The ID of an uploaded file to use as input. */
    // @DataMember(Name="file_id")
    FileId *string `json:"file_id,omitempty"`
}

/** @description File content part */
// @DataContract
type AiFileContent struct {
    AiContent
    /** @description The file input for this content. */
    // @DataMember(Name="file")
    File AiFile `json:"file"`
}

// @DataContract
type ChatResponse struct {
    /** @description A unique identifier for the chat completion. */
    // @DataMember(Name="id")
    Id string `json:"id"`
    /** @description A list of chat completion choices. Can be more than one if n is greater than 1. */
    // @DataMember(Name="choices")
    Choices []Choice `json:"choices"`
    /** @description The Unix timestamp (in seconds) of when the chat completion was created. */
    // @DataMember(Name="created")
    Created int64 `json:"created,omitempty"`
    /** @description The model used for the chat completion. */
    // @DataMember(Name="model")
    Model string `json:"model"`
    /** @description This fingerprint represents the backend configuration that the model runs with. */
    // @DataMember(Name="system_fingerprint")
    SystemFingerprint *string `json:"system_fingerprint,omitempty"`
    /** @description The object type, which is always chat.completion. */
    // @DataMember(Name="object")
    Object string `json:"object"`
    /** @description Specifies the processing type used for serving the request. */
    // @DataMember(Name="service_tier")
    ServiceTier *string `json:"service_tier,omitempty"`
    /** @description Usage statistics for the completion request. */
    // @DataMember(Name="usage")
    Usage AiUsage `json:"usage"`
    /** @description Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. */
    // @DataMember(Name="metadata")
    Metadata map[string]string `json:"metadata,omitempty"`
    // @DataMember(Name="responseStatus")
    ResponseStatus *ResponseStatus `json:"responseStatus,omitempty"`
}

/** @description Chat Completions API (OpenAI-Compatible) */
// @Route("/v1/chat/completions", "POST")
// @DataContract
type ChatCompletion struct {
    /** @description The messages to generate chat completions for. */
    // @DataMember(Name="messages")
    Messages []AiMessage `json:"messages"`
    /** @description ID of the model to use. See the model endpoint compatibility table for details on which models work with the Chat API */
    // @DataMember(Name="model")
    Model string `json:"model"`
    /** @description Parameters for audio output. Required when audio output is requested with modalities: [audio] */
    // @DataMember(Name="audio")
    Audio *AiChatAudio `json:"audio,omitempty"`
    /** @description Modify the likelihood of specified tokens appearing in the completion. */
    // @DataMember(Name="logit_bias")
    LogitBias map[int]int `json:"logit_bias,omitempty"`
    /** @description Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. */
    // @DataMember(Name="metadata")
    Metadata map[string]string `json:"metadata,omitempty"`
    /** @description Constrains effort on reasoning for reasoning models. Currently supported values are minimal, low, medium, and high (none, default). Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response. */
    // @DataMember(Name="reasoning_effort")
    ReasoningEffort *string `json:"reasoning_effort,omitempty"`
    /** @description An object specifying the format that the model must output. Compatible with GPT-4 Turbo and all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`. Setting Type to ResponseFormat.JsonObject enables JSON mode, which guarantees the message the model generates is valid JSON. */
    // @DataMember(Name="response_format")
    ResponseFormat *AiResponseFormat `json:"response_format,omitempty"`
    /** @description Specifies the processing type used for serving the request. */
    // @DataMember(Name="service_tier")
    ServiceTier *string `json:"service_tier,omitempty"`
    /** @description A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies. The IDs should be a string that uniquely identifies each user. */
    // @DataMember(Name="safety_identifier")
    SafetyIdentifier *string `json:"safety_identifier,omitempty"`
    /** @description Up to 4 sequences where the API will stop generating further tokens. */
    // @DataMember(Name="stop")
    Stop []string `json:"stop,omitempty"`
    /** @description Output types that you would like the model to generate. Most models are capable of generating text, which is the default: */
    // @DataMember(Name="modalities")
    Modalities []string `json:"modalities,omitempty"`
    /** @description Used by OpenAI to cache responses for similar requests to optimize your cache hit rates. */
    // @DataMember(Name="prompt_cache_key")
    PromptCacheKey *string `json:"prompt_cache_key,omitempty"`
    /** @description A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported. */
    // @DataMember(Name="tools")
    Tools []Tool `json:"tools,omitempty"`
    /** @description Constrains the verbosity of the model's response. Lower values will result in more concise responses, while higher values will result in more verbose responses. Currently supported values are low, medium, and high. */
    // @DataMember(Name="verbosity")
    Verbosity *string `json:"verbosity,omitempty"`
    /** @description What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. */
    // @DataMember(Name="temperature")
    Temperature *float64 `json:"temperature,omitempty"`
    /** @description An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and reasoning tokens. */
    // @DataMember(Name="max_completion_tokens")
    MaxCompletionTokens *int `json:"max_completion_tokens,omitempty"`
    /** @description An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. logprobs must be set to true if this parameter is used. */
    // @DataMember(Name="top_logprobs")
    TopLogprobs *int `json:"top_logprobs,omitempty"`
    /** @description An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. */
    // @DataMember(Name="top_p")
    TopP *float64 `json:"top_p,omitempty"`
    /** @description Number between `-2.0` and `2.0`. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. */
    // @DataMember(Name="frequency_penalty")
    FrequencyPenalty *float64 `json:"frequency_penalty,omitempty"`
    /** @description Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. */
    // @DataMember(Name="presence_penalty")
    PresencePenalty *float64 `json:"presence_penalty,omitempty"`
    /** @description This feature is in Beta. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend. */
    // @DataMember(Name="seed")
    Seed *int `json:"seed,omitempty"`
    /** @description How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs. */
    // @DataMember(Name="n")
    N *int `json:"n,omitempty"`
    /** @description Whether or not to store the output of this chat completion request for use in our model distillation or evals products. */
    // @DataMember(Name="store")
    Store *bool `json:"store,omitempty"`
    /** @description Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message. */
    // @DataMember(Name="logprobs")
    Logprobs *bool `json:"logprobs,omitempty"`
    /** @description Whether to enable parallel function calling during tool use. */
    // @DataMember(Name="parallel_tool_calls")
    ParallelToolCalls *bool `json:"parallel_tool_calls,omitempty"`
    /** @description Whether to enable thinking mode for some Qwen models and providers. */
    // @DataMember(Name="enable_thinking")
    EnableThinking *bool `json:"enable_thinking,omitempty"`
    /** @description If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a `data: [DONE]` message. */
    // @DataMember(Name="stream")
    Stream *bool `json:"stream,omitempty"`
}
